#!/usr/bin/env python3
"""
Vector Database Builder using Qdrant + Sentence Transformers
Generated by Journal Scout

Requirements:
  pip install qdrant-client sentence-transformers

Usage:
  python create_vectordb.py
"""

import os
import json
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from sentence_transformers import SentenceTransformer

# Configuration
PAPERS_DIR = "./papers"
DB_DIR = "./qdrant_db"
COLLECTION_NAME = "papers_vectordb"

def main():
    print("Loading embedding model...")
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    print("Initializing Qdrant...")
    client = QdrantClient(path=DB_DIR)  # Local storage
    # For Qdrant Cloud: client = QdrantClient(url="...", api_key="...")
    
    print(f"Processing papers from {PAPERS_DIR}...")
    documents = []
    metadatas = []
    
    for i, filename in enumerate(os.listdir(PAPERS_DIR)):
        if filename.endswith(('.txt', '.md')):
            filepath = os.path.join(PAPERS_DIR, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            title = filename
            if 'TITLE:' in content:
                title = content.split('TITLE:')[1].split('\n')[0].strip()
            
            documents.append(content)
            metadatas.append({"filename": filename, "title": title})
            print(f"  Loaded: {filename}")
    
    if not documents:
        print("No .txt or .md files found!")
        return
    
    print("\nGenerating embeddings...")
    embeddings = model.encode(documents, show_progress_bar=True)
    
    # Create collection
    client.recreate_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(size=len(embeddings[0]), distance=Distance.COSINE)
    )
    
    # Add points
    points = [
        PointStruct(
            id=i,
            vector=embeddings[i].tolist(),
            payload={"content": documents[i], **metadatas[i]}
        )
        for i in range(len(documents))
    ]
    
    client.upsert(collection_name=COLLECTION_NAME, points=points)
    
    print(f"\nâœ… Qdrant database created with {len(documents)} documents!")
    print(f"   Location: {DB_DIR}")
    
    # Export for Journal Scout
    export_data = {
        "name": COLLECTION_NAME,
        "createdAt": __import__('datetime').datetime.now().isoformat(),
        "dimension": len(embeddings[0]),
        "documents": [
            {
                "id": f"doc_{i}",
                "fileName": metadatas[i]["filename"],
                "content": documents[i],
                "embedding": embeddings[i].tolist(),
                "metadata": {"title": metadatas[i]["title"], "createdAt": __import__('datetime').datetime.now().isoformat()}
            }
            for i in range(len(documents))
        ]
    }
    
    with open(f"{COLLECTION_NAME}_export.json", 'w') as f:
        json.dump(export_data, f)
    print(f"   Exported: {COLLECTION_NAME}_export.json")

if __name__ == "__main__":
    main()
